---
# Copyright 2016 PingCAP, Inc.
# The Playbook of TiDB

# use ec2.py dynamic inventory

#    - meta: refresh_inventory

- name: prepare inventory config stage 1
  hosts: localhost
  tasks:
    - name: Gather EC2 facts.
      ec2_remote_facts:
        region: cn-north-1
        filters:
          "tag:ManagedBy": ansible
      register: aws_ec2_facts

    - name: set up deploy servers
      add_host:
        groups: "{{ item.tags.Type | default('unused') }}_servers"
        hostname: "{{ item.public_ip_address }}"
      when: item.tags.Type is defined and item.tags.ManagedBy == 'ansible'
      with_items: "{{ aws_ec2_facts.instances | selectattr('state', 'equalto', 'running') | list }}"

    - name: set up monitoring server
      add_host:
        groups: monitoring_servers
        hostname: "{{ groups.tidb_servers[0] }}"

    - name: set up monitored servers
      add_host:
        groups: monitored_servers
        hostname: "{{ item.public_ip_address }}"
      when: item.tags.ManagedBy is defined and item.tags.ManagedBy == 'ansible'
      with_items: "{{ aws_ec2_facts.instances | selectattr('state', 'equalto', 'running') | list }}"

    - name: write local inventory file to aws.ini.new
      template: src=aws.inventory.ini.j2 dest={{ playbook_dir }}/aws.ini.new


- name: initializing deployment target
  hosts: all
  roles:
  - common

- name: deploying monitoring agent
  hosts: monitored_servers
  roles:
    - node_exporter
  tasks:
    - name: restart node_exporter
      shell: cd {{ deploy_dir }}/scripts && ./stop_{{ item }}.sh; ./start_{{ item }}.sh
      with_items:
      - node_exporter

    - name: wait NodeExporter up
      wait_for: host={{ ansible_default_ipv4.address }} port={{ node_exporter_port }} state=present

# monitoring control machine

- name: deploying monitoring server
  hosts: monitoring_servers
  roles:
    - pushgateway
    - prometheus
    - grafana
  tasks:
    - name: restart monitoring modules
      shell: cd {{ deploy_dir }}/scripts && ./stop_{{ item }}.sh; ./start_{{ item }}.sh
      with_items:
        - pushgateway
        - prometheus
        - grafana

    - name: wait monitoring modules up
      wait_for: host={{ ansible_default_ipv4.address }} port={{ item }} state=present
      with_items:
        - "{{ pushgateway_port }}"
        - "{{ prometheus_port }}"

    - name: wait grafana up
      wait_for: host={{ ansible_default_ipv4.address }} port={{ grafana_port }} state=present
      notify:
        - import grafana data source
        - import grafana dashboards


  # deploying TiDB cluster

- name: deploying PD cluster
  hosts: pd_servers
  roles:
  - pd
  tasks:
  - name: restart PD
    shell: cd {{ deploy_dir }}/scripts && ./stop_{{ item }}.sh; ./start_{{ item }}.sh
    with_items:
    - pd

  - name: wait PD up
    wait_for: host={{ ansible_default_ipv4.address }} port={{ pd_client_port }} state=present

- name: deploying TiKV cluster
  hosts: tikv_servers
  roles:
  - tikv
  tasks:
  - name: restart TiKV
    shell: cd {{ deploy_dir }}/scripts && ./stop_{{ item }}.sh; ./start_{{ item }}.sh
    with_items:
    - tikv

  - name: wait TiKV up
    wait_for: host={{ ansible_default_ipv4.address }} port={{ tikv_port }} state=present

- name: deploying TiDB cluster
  hosts: tidb_servers
  roles:
  - { role: pump, when: "groups.binlog_servers | default(False)" }
  - tidb
  tasks:
  - name: restart pump
    shell: cd {{ deploy_dir }}/scripts && ./stop_{{ item }}.sh; ./start_{{ item }}.sh
    when: "groups.binlog_servers | default(False)"
    with_items:
    - pump

  - name: restart TiDB
    shell: cd {{ deploy_dir }}/scripts && ./stop_{{ item }}.sh; ./start_{{ item }}.sh
    with_items:
    - tidb

  - name: wait TiDB up
    wait_for: host={{ ansible_default_ipv4.address }} port={{ tidb_port }} state=present
